# Server Configuration
PORT=3000
NODE_ENV=development

# LLM Providers Configuration
DEFAULT_LLM_PROVIDER=huggingface
FALLBACK_ORDER=huggingface,mistral,deepseek,openrouter,codestral,mock

# Required: At least one LLM Provider API Key
HF_TOKEN=your_huggingface_token_here
MISTRAL_API_KEY=your_mistral_api_key_here
DEEPSEEK_API_KEY=your_deepseek_api_key_here
OPENROUTER_API_KEY=your_openrouter_api_key_here
CODESTRAL_API_KEY=your_codestral_api_key_here

# Optional: Additional Provider Tokens
CONTINUE_API_KEY=your_continue_api_key_here
ALIBABA_QWEN_API_KEY=your_alibaba_qwen_api_key_here
KIMI_API_KEY=your_kimi_api_key_here
CODECOPILOT_KEY=your_codecopilot_key_here

# Hugging Face Configuration
HF_USERNAME=LetsTryGPT
HF_SPACE_NAME=agent4-implementation

# GitHub Configuration
GITHUB_TOKEN=your_github_token_here
GITHUB_USERNAME=novusaevum

# Vercel Configuration
VERCEL_TOKEN=your_vercel_token_here
VERCEL_ORG_ID=your_vercel_org_id_here
VERCEL_PROJECT_ID=your_vercel_project_id_here
VERCEL_AI_GATEWAY_API_KEY=your_vercel_ai_gateway_key_here

# Logging
LOG_LEVEL=info

# Feature Flags
ENABLE_METRICS=true
ENABLE_TRACING=true

# Security
CORS_ORIGIN=*
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=100
